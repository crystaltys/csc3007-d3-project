{"Content: ":"The Self-Indication Assumption Doomsday argument rebuttal is an objection to the Doomsday argument (that there is only a 5% chance of more than twenty times the historic number of humans ever being born) by arguing that the chance of being born is not one, but is an increasing function of the number of people who will be born. This objection to the Doomsday Argument (DA), originally by Dennis Dieks (1992), developed by Bartha & Hitchcock (1999), and expanded by Ken Olum (2001), is that the possibility of an individual existing all depends on how many humans will ever exist (N). If N is big, then the chance of said individual existing is higher than if only a few humans will ever exist. If the individual does exist, this is evidence that N is high. The argument is sometimes expressed in an alternative way by having the posterior marginal distribution of n based on N without explicitly invoking a non-zero chance of existing. The Bayesian inference mathematics are identical. The name for this attack within the DA community is the \"Self-Indication Assumption\" (SIA), proposed by one of its opponents, the DA-advocate Nick Bostrom. His (2000) definition reads: A development of Dieks's original paper by Kopf, Krtous and Page (1994), showed that the SIA precisely cancels out the effect of the Doomsday Argument, and therefore, one's birth position (n) gives no information about the total number of humans that will exist (N). This conclusion of SIA is uncontroversial with modern DA-proponents, who instead question the validity of the assumption itself, not the conclusion which would follow, if the SIA were true. The SIA-mathematics considers the chance of being the nth human as being conditioned on the joint probability of two separate events, both of which must be true: This means that the pdf for n, is concentrated at P(n = 0) = 1 - P(b), and that for P(n > 0) the marginal distribution can be calculated from the conditional: J. Richard Gott's DA could be formulated similarly up to this point, where it has P(b | N) = P(b) = 1, producing Gott's inference of n from N. However, Dennis Dieks argues that P(b) < 1, and that P(b | N) rises proportionally in N (which is a SIA). This can be expressed mathematically: The SIA\u2019s effect was expressed by Page et al. as Assumption 2 for the prior probability distribution, P(N): They note that similar assumptions had been dismissed by Leslie on the grounds that: \"it seems wrong to treat ourselves as if we were once immaterial souls harbouring hopes of becoming embodied, hopes that would have been greater, the greater the number of bodies to be created.\" (1992) One argument given for P(b | N) rising in N that does not create Leslie\u2019s \u201cimmaterial souls\u201d is the possibility of being born into any of a large number of universes within a multiverse. A person can only be born into one, so the indifference principle within this (humans-across-universes) reference class would mean that the chance of being born into a particular universe is proportional to its weight in humans, N. (Echoing the weak anthropic principle.) Whatever the reasoning, the essential idea of the Self-Indication Assumption is that the prior probability of birth into this universe is rising in N, and is generally considered to be proportional to N. (The following discussion assumes they are proportional so P(b | N) = 2 P(b | 2N), since other functions increasing in N produce similar results.) Therefore: To clarify the exposition, Gott\u2019s vague prior N distribution is \u2018capped\u2019 at some \u201cuniversal carrying capacity\u201d, Ω {\\displaystyle \\Omega } . (This prevents N\u2019s distribution being an improper prior.) Ω {\\displaystyle \\Omega } is the largest possible value for N if all living space in the 'universe' is consumed. The Ω {\\displaystyle \\Omega } limit has no specified upper bounds (to habitable planets in the Galaxy, say) but makes N\u2019s posterior distribution more tractable: The ln \u2061 ( Ω ) {\\displaystyle \\ln(\\Omega )} factor normalizes the N\u2019s probability, allowing calculation of the marginal P(n > 0) by integration of P(b|N) across the [1, Ω {\\displaystyle \\Omega } ] range of possible N: This range starts at n rather than 1, because n can\u2019t be greater than N. It uses the calculation above for n\u2019s distribution given N, and implies: Substituting these marginals into the conditional equation (assuming N below Ω {\\displaystyle \\Omega } ) gives: The chance of doomsday before an arbitrary factor of the current population, x, is born can be inferred, by integrating the chance of N having any value above xn. (Normally x = 20.) Therefore, given the posterior information that we have been born and that we are nth in line: For any factor, x << ( Ω {\\displaystyle \\Omega } / n), of the current population: The finite Ω {\\displaystyle \\Omega } is essential to this solution in order to produce finite integrals. In a bounded universe, Ω {\\displaystyle \\Omega } actually must be finite, although this is not usually an argument used by those proposing the SIA rebuttal. However, other proponents of indefinite survival of human (and posthuman) intelligence have postulated a finite endpoint, as the (extremely high) \u201cOmega\u201d. Specifying any finite upper limit, Ω {\\displaystyle \\Omega } , was not a part of Dieks's argument, and critics of the SIA have argued that an infinite upper bound on N creates an Improper integral (or summation) in the bayesian inference on N, which is a challenge to the logic of the critique. (For example Eastmond, and Bostrom, who argues that if the SIA cannot rule out an infinite number of potential humans, it is fatally flawed.) The unbounded vague prior is scale invariant, in that the mean is arbitrary. Therefore no finite value can be selected with more than a 50% chance of being above N (the marginal distribution of N). Olum's critique depends on such a limit existing; without this his critique is technically not applicable. Therefore it must be cautioned that the simplification here (to bound N's distribution at Ω {\\displaystyle \\Omega } ) omits a significant hurdle to the credibility of the Self-Indication Assumption Doomsday argument rebuttal. Many people, (such as Bostrom) believe the leading candidate for Doomsday argument refutation is a Self-Indication Assumption of some kind. It is popular partly because it is a purely Bayesian argument which accepts some of the DA's premises (such as the Indifference and Copernican principles). Other observations: Under the Self-Indication Assumption the 'reference class' of which we are part includes a potentially vast number of the unborn (at least into this universe). In order to overturn the conventional DA calculation so completely the reservoir of souls (potential births) in the reference class must be astoundingly large. For instance, the certain-birth DA estimates the chance of reaching the trillionth ( 10 12 {\\displaystyle 10^{12}} th) birth at around 5%; to shift this probability above 90% the SIA requires a potential number of humans ( Ω {\\displaystyle \\Omega } ) in the order of 10 24 {\\displaystyle 10^{24}} (a septillion births). This might be feasible physically, and is also possible within the conventional DA model (though staggeringly unlikely). However, the SIA differs from the normal DA in having the reference class include all septillion unborn potential-humans at this point in history, when only sixty billion have been born. Including unborn people in the reference class we sample from means including in the reference class things for which we can never have any evidence. This puts the SIA at odds with philosophical approaches requiring strictly falsifiable constructs, such as logical positivism. It can be hard to visualize how the Self-Indication Assumption changes the distribution because everyday cases where a null result can be returned don't change the statistics significantly. The following two examples of estimating the size of a darkened space show how the probability shift can occur: The Bayesian inference shifts from the cloak-room case to the lost-property case, because of the chance that the coat would not be found in the aisle it was found in, and some estimate of the aisle's dimensions. Using the SIA Bayesian inference equation with Ω {\\displaystyle \\Omega } = 100, n = 1, x = 20 gives the chance that the aisle is above 20 feet long in the Lost-property case: The confidence that the unseen space is longer than 20 feet is directly analogous to the confidence that the human race will become more than 20 times as numerous as it has been. Using an Ω {\\displaystyle \\Omega } of one hundred times the current value only increases the subjective chance seven times (from 5% to 35%), but this is a very small limit for the purposes of exposition. The SIA is not an assumption or axiom of Dieks' system. In fact, as stated, the negation of the SIA is a theorem of Dieks' system. A proposition similar to the SIA can be derived from Dieks' system, but it is necessary to revise the SIA to limit it to situations where a person doesn't know the date or their birth order number. Even this related proposition is not an axiom of Dieks. It is a theorem, derived from other fundamental assumptions. In Dieks, they may never have been born and the end of the human race is independent of their birth order number. A proposition related to the SIA, but not the SIA itself, can be derived from these assumptions. Hence, no one assumes the SIA. It should be called the Self-Indication Corollary, perhaps. Katja Grace argues that while SIA overcomes the standard doomsday argument, when combined with an assumption of a Great Filter, SIA leads to another kind of doomsday prediction. The reasoning is as follows. In some worlds, the filter may be early\u2014some time before the advent of a technological civilization like ours. In other worlds, the filter may be late\u2014between the advent of technological civilization and galactic colonization. Collectively, the worlds with mostly late filters have many more instances of life at the human level of development, so SIA, together with the knowledge that we are at the human-level stage, implies we're probably in one of the worlds with a late filter. In other words, the risk of extinction is higher than we would have naively supposed.[1][2][3]","Title":"Self-Indication Assumption Doomsday argument rebuttal - Wikipedia","KeyID":"11958","URL":"https://en.wikipedia.org/wiki/Self-Indication_Assumption_Doomsday_argument_rebuttal"}