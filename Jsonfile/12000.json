{"Content: ":"Biotechnology risk is a form of existential risk that could come from biological sources, such as genetically engineered biological agents.[1][2] The origin of such a high-consequence pathogen could be a deliberate release (in the form of bioterrorism or biological weapons), an accidental release, or a naturally occurring event. A chapter on biotechnology and biosecurity was published in Nick Bostrom's 2008 anthology Global Catastrophic Risks, which covered risks including as viral agents.[3] Since then, new technologies like CRISPR and gene drives have been introduced. While the ability to deliberately engineer pathogens has been constrained to high-end labs run by top researchers, the technology to achieve this (and other astonishing feats of bioengineering) is rapidly becoming cheaper and more widespread. Such examples include the diminishing cost of sequencing the human genome (from $10 million to $1,000), the accumulation of large datasets of genetic information, the discovery of gene drives, and the discovery of CRISPR.[4] Biotechnology risk is therefore a credible explanation for the Fermi paradox.[5] Pathogens may be intentionally or unintentionally genetically modified to change their characteristics, including virulence or toxicity.[2] When intentional, these mutations can serve to adapt the pathogen to a laboratory setting, understand the mechanism of transmission or pathogenesis, or in the development of therapeutics. Such mutations have also been used in the development of biological weapons, and dual-use risk continues to be a concern in the research of pathogens.[6] The greatest concern is frequently associated with gain-of-function mutations, which confer novel or increased functionality, and the risk of their release. Gain-of-function research on viruses has been occurring since the 1970s, and came to notoriety after influenza vaccines were serially passed through animal hosts.[citation needed] A group of Australian researchers unintentionally changed characteristics of the mousepox virus while trying to develop a virus to sterilize rodents as a means of biological pest control.[2][7][8] The modified virus became highly lethal even in vaccinated and naturally resistant mice.[9] In 2011, two laboratories published reports of mutational screens of avian influenza viruses, identifying variant which become transmissible through the air between ferrets. These viruses seem to overcome an obstacle which limits the global impact of natural H5N1.[10][11] In 2012, scientists further screened point mutations of the H5N1 virus genome to identify mutations which allowed airborne spread.[12][13] While the stated goal of this research was to improve surveillance and prepare for influenza viruses which are of particular risk in causing a pandemic,[14] there was significant concern that the laboratory strains themselves could escape.[15] Marc Lipsitch and Alison P. Galvani coauthored a paper in PLoS Medicine arguing that experiments in which scientists manipulate bird influenza viruses to make them transmissible in mammals deserve more intense scrutiny as to whether or not their risks outweigh their benefits.[16] Lipsitch also described influenza as the most frightening \"potential pandemic pathogen\".[17] In 2014, the United States instituted a moratorium on gain-of-function research into influenza, MERS, and SARS.[18] This was in response to the particular risks these airborne pathogens pose. However, many scientists opposed the moratorium, arguing that this limited their ability to develop antiviral therapies.[19] The scientists argued gain-of-function mutations were necessary, such as adapting MERS to laboratory mice so it could be studied. The National Science Advisory Board for Biosecurity also has instituted rules for research proposals using gain-of-function research of concern.[20] The rules outline how experiments to be evaluated for risks, safety measures, and potential benefits; prior to funding. In order to limit access to minimize the risk of easy access to genetic material from pathogens, including viruses, the members of the International Gene Synthesis Consortium screen orders for regulated pathogen and other dangerous sequences.[21] Orders for pathogenic or dangerous DNA are verified for customer identity, barring customers on governmental watch lists, and only to institutions \"demonstrably engaged in legitimate research\". Following surprisingly fast advances in CRISPR editing, an international summit proclaimed in December 2015 that it was \"irresponsible\" to proceed with human gene editing until issues in safety and efficacy were addressed.[22] One of the mechanisms that CRISPR can cause existential risk is through gene drives, which are said to have potential to \"revolutionize\" ecosystem management.[23] Gene drives are a novel technology that have potential to make genes spread through wild populations like wildfire. They have the potential to quickly spread resistance genes against malaria in order to rebuff the malaria parasite P. falciparum.[24] These gene drives were originally engineered in January 2015 by Ethan Bier and Valentino Gantz \u2013 this editing was spurred by the discovery of CRISPR-Cas9. In late 2015, DARPA started to study approaches that could halt gene drives if they went out of control and threatened biological species.[25]","Title":"Biotechnology risk - Wikipedia","KeyID":"12000","URL":"https://en.wikipedia.org/wiki/Biotechnology_risk"}